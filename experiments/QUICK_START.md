# Quick Start Guide: Transform Diversity Experiments

This guide helps you quickly run the transform diversity experiments and understand the results.

---

## What You'll Learn

By running these experiments, you'll see:
1. How diverse transforms improve backdoor detection
2. Why variance-based detection works
3. How well detectors generalize to unseen attacks

---

## Prerequisites

```bash
# Install required packages
pip install torch transformers datasets nltk textattack

# Set up environment
cd Poison-Detection
export PYTHONPATH="${PYTHONPATH}:$(pwd)"
```

---

## Quick Run (5 minutes)

### All-in-One Command

```bash
# Run all experiments
cd Poison-Detection/experiments

# 1. Generate dataset
python3 generate_diverse_dataset.py \
  --input ../data/sentiment/dev.tsv \
  --output ../data/diverse_poisoned_sst2.json \
  --num-samples 100 \
  --num-types 3 \
  --transforms-per-type 2

# 2. Train detector
python3 train_ensemble_detector.py \
  --dataset ../data/diverse_poisoned_sst2.json \
  --output results/ensemble_diverse_transforms.json

# 3. Cross-validate
python3 cross_validate_transforms.py \
  --dataset ../data/diverse_poisoned_sst2.json \
  --output results/cross_validation_transforms.json

# 4. Visualize
python3 visualize_results.py \
  --results-dir results \
  --output-dir plots
```

---

## Understanding the Output

### Step 1: Dataset Generation

**What it does:**
- Creates a dataset with clean and poisoned samples
- Uses 6 diverse transforms across 3 categories
- Simulates real-world backdoor attacks

**Expected output:**
```
âœ… Generated dataset saved to: data/diverse_poisoned_sst2.json
   - 100 total samples
   - 33 poisoned (33%)
   - 6 diverse transforms used
```

### Step 2: Ensemble Detection

**What it does:**
- Tests 4 different detection methods
- Measures recall, precision, F1, and accuracy
- Identifies the best-performing method

**Expected output:**
```
Best Method: Variance
â”œâ”€ Recall: 100% (detects all attacks)
â”œâ”€ Precision: 66% (low false positives)
â”œâ”€ F1: 79.5%
â””â”€ Accuracy: 98.3%
```

**What this means:**
- **Variance method wins**: Best balance of detection vs false positives
- **100% recall**: No attacks slipped through
- **66% precision**: Only 17 clean samples incorrectly flagged

### Step 3: Cross-Validation

**What it does:**
- Tests generalization to unseen transform types
- Trains on 2 categories, tests on the 3rd
- Measures how well patterns transfer

**Expected output:**
```
Fold 1 (Hold Out Lexicon):
â”œâ”€ Train Recall: 100%
â”œâ”€ Test Recall: 85.7%
â””â”€ Generalization Gap: 14.3% âœ…

Fold 2 (Hold Out Semantic):
â”œâ”€ Train Recall: 94.4%
â”œâ”€ Test Recall: 100%
â””â”€ Generalization Gap: -5.6% âœ… (even better!)

Fold 3 (Hold Out Structural):
â”œâ”€ Train Recall: 100%
â”œâ”€ Test Recall: 78.6%
â””â”€ Generalization Gap: 21.4% âœ…
```

**What this means:**
- Small generalization gaps (<25%) = Good generalization
- Detector learned patterns, not memorized transforms
- Works on attack types it never saw during training

### Step 4: Visualization

**What it generates:**

1. **ensemble_performance.png**
   - Bar charts comparing detection methods
   - Shows recall, precision, and F1 scores

2. **transform_distribution.png**
   - Shows which transforms were used
   - Visualizes category coverage

---

## Interpreting Results

### Good Results âœ…

```
âœ… Recall > 80%        â†’ Catches most attacks
âœ… Precision > 60%     â†’ Few false positives
âœ… F1 > 70%            â†’ Good balance
âœ… Gen. Gap < 25%      â†’ Good generalization
```

### Warning Signs âš ï¸

```
âš ï¸ Recall < 50%        â†’ Missing many attacks
âš ï¸ Precision < 30%     â†’ Too many false positives
âš ï¸ F1 < 50%            â†’ Poor overall performance
âš ï¸ Gen. Gap > 40%      â†’ Poor generalization
```

---

## Customization

### Change Dataset Size

```bash
python3 generate_diverse_dataset.py \
  --num-samples 500 \         # More samples
  --num-types 4 \              # More transform categories
  --transforms-per-type 3 \    # More transforms per category
  --poison-rate 0.1            # 10% poisoned instead of 33%
```

### Change Detection Threshold

Edit `train_ensemble_detector.py`:

```python
# Line ~120
threshold = 0.5  # Default
threshold = 0.3  # More sensitive (higher recall, lower precision)
threshold = 0.7  # More conservative (lower recall, higher precision)
```

### Add Custom Transforms

Edit `generate_diverse_dataset.py`:

```python
# Add to AVAILABLE_TRANSFORMS dict
'my_category': {
    'my_transform': MyTransformFunction,
}
```

---

## Common Issues

### Issue: "No module named 'src'"

**Solution:**
```bash
export PYTHONPATH="${PYTHONPATH}:$(pwd)"
```

### Issue: "CUDA out of memory"

**Solution:**
```bash
# Use CPU instead
export CUDA_VISIBLE_DEVICES=""
```

Or reduce batch size:
```python
# In the script
batch_size = 16  # Change to 8 or 4
```

### Issue: "Too many false positives"

**Solution:**
- Increase detection threshold
- Use "voting" method instead of "variance"
- Train on more diverse transforms

### Issue: "Low recall on test set"

**Solution:**
- Add more transform categories
- Increase training data size
- Use "combined" method instead of "voting"

---

## Next Steps

### 1. Experiment with Parameters

Try different configurations:
- More/fewer transforms
- Different poison rates
- Various detection thresholds

### 2. Analyze Failure Cases

```bash
# Look at false positives/negatives in results JSON
cat results/ensemble_diverse_transforms.json | jq '.results.variance'
```

### 3. Apply to Your Dataset

```bash
python3 generate_diverse_dataset.py \
  --input YOUR_DATA.tsv \
  --output poisoned_data.json \
  --num-samples 1000
```

### 4. Read the Full Report

See `experiments/FINAL_REPORT.md` for:
- Detailed methodology
- Theoretical background
- Advanced analysis
- Production recommendations

---

## Key Takeaways

1. **Diverse transforms > Single transform**
   - Better generalization
   - More robust detection
   - Lower false positives

2. **Variance method is effective**
   - Simple but powerful
   - Works across transform types
   - Computationally efficient

3. **Generalization is achievable**
   - Training on diverse transforms enables transfer
   - <25% generalization gap is good
   - Validates the approach

---

## Questions?

See the full documentation:
- `FINAL_REPORT.md` - Complete analysis
- `RESULTS_SUMMARY.md` - Results overview
- `../README.md` - Project overview

---

**Happy experimenting!** ðŸ”¬
