# Poison Detection Toolkit

> Influence-based detection methods for identifying poisoned training samples in instruction-tuned language models

## Overview

This toolkit provides state-of-the-art influence-based detection methods for identifying poisoned data in language model training sets using Kronfluence (EK-FAC) to compute influence scores.

**Key Features:**
- üîç 14 different detection methods (statistical, ML-based, ensemble)
- ‚ö° GPU-accelerated with CUSOLVER error fix
- üìä Comprehensive evaluation metrics
- üéØ Tested on multiple attack types
- üöÄ Multi-GPU support on NVIDIA L40

---

## Installation

### Prerequisites
- Python >= 3.8
- PyTorch >= 2.0.0
- CUDA-capable GPU (recommended)

### Install from source

```bash
git clone https://github.com/anonymous/Poison-Detection.git
cd Poison-Detection
pip install -e .
```

---

## Quick Start

### Basic Usage

```python
from poison_detection.data.poisoner import DataPoisoner
from poison_detection.detection.detector import InfluenceDetector
from poison_detection.influence.analyzer import InfluenceAnalyzer
from transformers import AutoModelForSeq2SeqLM, AutoTokenizer

# 1. Load model
model = AutoModelForSeq2SeqLM.from_pretrained("google/t5-small-lm-adapt")
tokenizer = AutoTokenizer.from_pretrained("google/t5-small-lm-adapt")

# 2. Poison dataset
poisoner = DataPoisoner(trigger_word="cf", target_label=1, poison_ratio=0.05)
poisoned_dataset, poison_indices = poisoner.poison_dataset(dataset)

# 3. Compute influence scores
analyzer = InfluenceAnalyzer(model=model, task_name="sentiment")
influence_scores = analyzer.compute_influence(poisoned_dataset)

# 4. Detect poisons
detector = InfluenceDetector()
detected = detector.detect_poisons(
    influence_scores=influence_scores,
    method="percentile_high",
    threshold=0.85
)

# 5. Evaluate
metrics = detector.evaluate_detection(detected, poison_indices)
print(f"Precision: {metrics['precision']:.2%}")
print(f"Recall: {metrics['recall']:.2%}")
print(f"F1 Score: {metrics['f1']:.2%}")
```

### GPU-Accelerated Experiments

```bash
# Run on GPU with automatic CUSOLVER error handling
python experiments/run_experiments_gpu_fixed.py \
  --task polarity \
  --num_train_samples 100 \
  --num_test_samples 50 \
  --damping_factor 0.01
```

---

## Experimental Results

### Hardware & Setup
- **Model:** T5-small (77M parameters) - `google/t5-small-lm-adapt`
- **Task:** Sentiment Analysis (polarity dataset)
- **GPU:** NVIDIA L40 (46GB memory)
- **Framework:** Kronfluence with EK-FAC factorization

### Experiment Design

| Experiment | Dataset Size | Poison Ratio | Attack Type | Runtime |
|------------|--------------|--------------|-------------|---------|
| Baseline | 500 | 20% | Single | 3.22s |
| Standard | 1000 | 10% | Single | 3.87s |
| Multi-trigger | 1000 | 10% | Multi | 6.00s |
| Large dataset | 2000 | 5% | Single | 6.22s |

### Performance Results

#### Best Performing Methods

**1. Percentile (85% high) - RECOMMENDED**
- Best F1: 10.74% (at 10% poison ratio)
- Consistent across all experiments
- Balanced precision/recall

**2. Top-K lowest influence**
- Best F1: 23.46% (at 20% poison ratio)
- Excellent for high poison ratios

**3. Local Outlier Factor**
- F1: ~10% (at 10% poison ratio)
- Good for scattered poison patterns

#### Detection Performance by Poison Ratio

| Poison Ratio | Dataset Size | Precision | Recall | F1 Score |
|--------------|--------------|-----------|--------|----------|
| 20% | 500 | 23.75% | 23.17% | **23.46%** |
| 10% | 1000 | 11.76% | 9.88% | **10.74%** |
| 5% | 2000 | 7.35% | 5.95% | **6.58%** |

### GPU Acceleration Results

**Successful GPU Experiment (Dec 2025):**
- **Configuration**: 50 train, 25 test samples
- **Status**: ‚úÖ Complete success with CUSOLVER fix
- **Runtime**: ~90 seconds
  - Eigendecomposition: 30s (145/145 matrices)
  - Pairwise scores: 60s
- **GPU Usage**: 40 GB memory
- **Baseline Influence**:
  - Mean: -101.53
  - Std: 426.21
  - Range: [-8310.45, 2624.56]

---

## Detection Methods

### 14 Methods Tested

1. ‚≠ê **Percentile (85% high)** - BEST overall
2. ‚úÖ **Top-K lowest influence** - Best for high poison ratio
3. ‚úÖ **Local Outlier Factor** - Good for outliers
4. Low variance
5. High variance
6. High influence ratio
7. Low influence ratio
8. Percentile (15% low)
9. Isolation Forest
10. One-Class SVM
11. Robust Covariance
12. Ensemble (basic)
13. Ensemble (ML)
14. Top-K highest influence

---

## Usage Examples

### Custom Detection

```python
detector = InfluenceDetector()

# Try different methods
methods = ["percentile_high", "top_k_low", "local_outlier_factor"]
for method in methods:
    detected = detector.detect_poisons(
        influence_scores=scores,
        method=method,
        threshold=0.85
    )
    metrics = detector.evaluate_detection(detected, true_indices)
    print(f"{method}: F1={metrics['f1']:.2%}")
```

### Ensemble Detection

```python
from poison_detection.detection.ensemble_detector import EnsembleDetector

ensemble = EnsembleDetector(
    methods=[
        ("percentile_high", {"threshold": 0.85}),
        ("top_k_low", {"k": 100}),
        ("local_outlier_factor", {})
    ],
    voting="soft",
    weights=[0.5, 0.3, 0.2]
)

detected = ensemble.detect_poisons(influence_scores)
```

### GPU Multi-Device

```python
# Automatically uses all available GPUs
CUDA_VISIBLE_DEVICES=0,1,2,3 python experiments/run_transform_experiments.py \
  --task polarity \
  --num_train_samples 1000
```

---

## Troubleshooting

### CUSOLVER Error (Fixed in Dec 2025)

**Error**: `torch._C._LinAlgError: cusolver error: CUSOLVER_STATUS_INVALID_VALUE`

**Solution**: Use the patched script (includes automatic fix):
```bash
python experiments/run_experiments_gpu_fixed.py --damping_factor 0.01
```

### Out of Memory

```python
# Reduce batch size
analyzer.compute_influence(dataset, per_device_batch_size=2)

# Increase damping factor
analyzer = InfluenceAnalyzer(model=model, damping_factor=0.01)
```

### Low Performance

- Use at least 10% poison ratio
- Try `percentile_high` with threshold 0.85
- Ensure 100+ poison samples minimum

---

## Key Findings

1. **Poison Ratio Impact**: Detection performance correlates strongly with poison ratio. Halving ratio halves metrics.
2. **Best Method**: Percentile (85% high) most consistent across experiments
3. **Scalability**: Linear scaling ~2.2ms per sample
4. **Multi-trigger**: No difference vs single trigger attacks
5. **GPU Acceleration**: Successfully fixed CUSOLVER errors, enabling full GPU utilization

---

## Recommendations

### For Production
1. Use `percentile_high` (threshold=0.85)
2. Minimum 500 samples, 10% poison ratio
3. Expected ~10% precision at 10% poison ratio
4. Budget ~2-3ms per sample

### For Research
1. Test higher poison ratios (15-30%)
2. Experiment with ensemble methods
3. Try larger models (T5-base, T5-large)
4. Explore adaptive thresholds

---

## Project Structure

```
Poison-Detection/
‚îú‚îÄ‚îÄ poison_detection/
‚îÇ   ‚îú‚îÄ‚îÄ data/              # Data handling, poisoning, transforms
‚îÇ   ‚îú‚îÄ‚îÄ detection/         # 14 detection methods
‚îÇ   ‚îú‚îÄ‚îÄ influence/         # Kronfluence integration
‚îÇ   ‚îú‚îÄ‚îÄ config/            # Configuration
‚îÇ   ‚îî‚îÄ‚îÄ utils/             # GPU patches, utilities
‚îú‚îÄ‚îÄ experiments/
‚îÇ   ‚îú‚îÄ‚îÄ results/           # Experiment outputs
‚îÇ   ‚îú‚îÄ‚îÄ run_transform_experiments.py
‚îÇ   ‚îî‚îÄ‚îÄ run_experiments_gpu_fixed.py  # GPU with CUSOLVER fix
‚îî‚îÄ‚îÄ README.md
```

---

## Citation

```bibtex
@misc{poison-detection-2025,
  title={Influence-Based Poison Detection for Instruction-Tuned Language Models},
  author={Anonymous},
  year={2025}
}
```

---

## License

MIT License - See LICENSE file for details

---

**Built for safer AI training**
